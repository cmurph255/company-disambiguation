{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5db0eaf4-2f43-4c19-861d-df6fa91c917f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 787 | Train: 709 | Val: 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cmurp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 3 epochs, ~36 steps, warmup 4 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cmurp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1011: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "c:\\users\\cmurp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\amp\\grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2b7fbaa905452299209f12fa79bb0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c16859026164d2ead1ef740883650ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4f3f12840843f68eb7e427429eb84b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a68447d6bb49c887b0be8713b6f5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to finetuned-company-matcher\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation, models\n",
    "from sentence_transformers.util import cos_sim\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "\n",
    "########################################\n",
    "# Config you can tweak\n",
    "########################################\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "TRAIN_CSV  = \"training-data.csv\"   # your combined labeled data\n",
    "OUTPUT_DIR = \"finetuned-company-matcher\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS     = 3\n",
    "LEARNING_RATE = 2e-5\n",
    "WARMUP_RATIO  = 0.1   # % of total steps used for warmup\n",
    "VAL_SPLIT     = 0.1   # percent of rows to hold out for eval\n",
    "SEED          = 42\n",
    "\n",
    "\n",
    "\n",
    "def normalize_company_name(x: str) -> str:\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    x = str(x)\n",
    "    x = x.lower()\n",
    "    # remove punctuation -> space\n",
    "    x = re.sub(r\"[^a-z0-9\\s]\", \" \", x)\n",
    "    # collapse repeated whitespace\n",
    "    x = re.sub(r\"\\s+\", \" \", x).strip()\n",
    "    return x\n",
    "\n",
    "########################################\n",
    "# 0. Reproducibility\n",
    "########################################\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "########################################\n",
    "# 1. Load data\n",
    "########################################\n",
    "df = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "# basic safety checks\n",
    "required_cols = {\"sentence1\", \"sentence2\", \"similarity\"}\n",
    "missing = required_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Your CSV is missing columns: {missing}\")\n",
    "\n",
    "# normalize text the same way you'll normalize at inference time\n",
    "df[\"s1_norm\"] = df[\"sentence1\"].apply(normalize_company_name)\n",
    "df[\"s2_norm\"] = df[\"sentence2\"].apply(normalize_company_name)\n",
    "\n",
    "# shuffle\n",
    "df = df.sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "# train/val split\n",
    "n_total = len(df)\n",
    "n_val   = max(1, int(n_total * VAL_SPLIT))\n",
    "df_val  = df.iloc[:n_val].reset_index(drop=True)\n",
    "df_train= df.iloc[n_val:].reset_index(drop=True)\n",
    "\n",
    "print(f\"Total rows: {n_total} | Train: {len(df_train)} | Val: {len(df_val)}\")\n",
    "\n",
    "########################################\n",
    "# 2. Build InputExamples\n",
    "########################################\n",
    "train_examples = [\n",
    "    InputExample(\n",
    "        texts=[row[\"s1_norm\"], row[\"s2_norm\"]],\n",
    "        label=float(row[\"similarity\"])\n",
    "    )\n",
    "    for _, row in df_train.iterrows()\n",
    "]\n",
    "\n",
    "val_sentences1 = df_val[\"s1_norm\"].tolist()\n",
    "val_sentences2 = df_val[\"s2_norm\"].tolist()\n",
    "val_scores     = df_val[\"similarity\"].astype(float).tolist()\n",
    "\n",
    "########################################\n",
    "# 3. Load base model\n",
    "########################################\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "# Optional: you can adjust the pooling or dense layer, but MiniLM defaults are fine.\n",
    "# We’ll just train it end-to-end with a cosine similarity loss.\n",
    "\n",
    "########################################\n",
    "# 4. Loss + Dataloader\n",
    "########################################\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "########################################\n",
    "# 5. Evaluator for validation\n",
    "########################################\n",
    "# This will compute cosine sim(model(s1), model(s2)) and correlate with labels.\n",
    "evaluator = evaluation.EmbeddingSimilarityEvaluator(\n",
    "    val_sentences1,\n",
    "    val_sentences2,\n",
    "    val_scores,\n",
    "    main_similarity=evaluation.SimilarityFunction.COSINE\n",
    ")\n",
    "\n",
    "########################################\n",
    "# 6. Training\n",
    "########################################\n",
    "num_train_steps = math.ceil(len(train_dataloader) * EPOCHS)\n",
    "warmup_steps    = math.ceil(num_train_steps * WARMUP_RATIO)\n",
    "\n",
    "print(f\"Training for {EPOCHS} epochs, ~{num_train_steps} steps, warmup {warmup_steps} steps\")\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=evaluator,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer_params={\"lr\": LEARNING_RATE},\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=OUTPUT_DIR,\n",
    "    show_progress_bar=True,\n",
    "    use_amp=True  # mixed precision for speed, if GPU supports it; safe on CPU too\n",
    ")\n",
    "\n",
    "print(f\"Model saved to {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a5a320-cedd-4f2e-92bf-694ba4ec06b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aspire Financial</td>\n",
       "      <td>PUTNAM Financial</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assetmark Financial Partners</td>\n",
       "      <td>Tradewinds Financial Partners</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bigelow Asset Management</td>\n",
       "      <td>TCI Asset Management</td>\n",
       "      <td>0.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pin Wealth Partners</td>\n",
       "      <td>Safeguard Wealth Partners</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Qtrade Wealth Partners</td>\n",
       "      <td>Usmart Wealth Partners</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>University Financial Trust</td>\n",
       "      <td>University Asset Management Group</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>Safeguard Capital Management</td>\n",
       "      <td>Safeguard Advisory Group</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>Tavira Financial Trust</td>\n",
       "      <td>Tavira Advisory</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>Analog Financial Trust</td>\n",
       "      <td>Analog Investment Company</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>Pine Capital Advisors</td>\n",
       "      <td>Pine Financial</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>787 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        sentence1                          sentence2  \\\n",
       "0                Aspire Financial                   PUTNAM Financial   \n",
       "1    Assetmark Financial Partners      Tradewinds Financial Partners   \n",
       "2        Bigelow Asset Management               TCI Asset Management   \n",
       "3             Pin Wealth Partners          Safeguard Wealth Partners   \n",
       "4          Qtrade Wealth Partners             Usmart Wealth Partners   \n",
       "..                            ...                                ...   \n",
       "782    University Financial Trust  University Asset Management Group   \n",
       "783  Safeguard Capital Management           Safeguard Advisory Group   \n",
       "784        Tavira Financial Trust                    Tavira Advisory   \n",
       "785        Analog Financial Trust          Analog Investment Company   \n",
       "786         Pine Capital Advisors                     Pine Financial   \n",
       "\n",
       "     similarity  \n",
       "0         0.059  \n",
       "1         0.079  \n",
       "2         0.063  \n",
       "3         0.051  \n",
       "4         0.073  \n",
       "..          ...  \n",
       "782       0.600  \n",
       "783       0.600  \n",
       "784       0.600  \n",
       "785       0.600  \n",
       "786       0.600  \n",
       "\n",
       "[787 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880b1aba-106a-49cd-acfd-0d6a2e9c4a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
